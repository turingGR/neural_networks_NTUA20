{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification III: evaluation metrics.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6emEWnHI-78w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993287083,"user_tz":-120,"elapsed":13315,"user":{"displayName":"Savvas Sifnaios","photoUrl":"","userId":"09827535660052856195"}},"outputId":"536a8023-2a7e-4543-ed31-27628ff8e840"},"source":[" # κάνουμε update τις βιβλιοθήκες μας\n","!pip install -U scikit-learn\n","!pip install --upgrade pandas\n","!pip install -U scipy\n","!pip install --upgrade numpy "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n","Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n","Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n","Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.4)\n","Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NO_qd5W7N4pX"},"source":["# Αξιολόγηση ταξινόμησης με ακρίβεια, ανάκληση και F1, μέσοι όροι\n","Η πιστότητα είναι μια πολύ χρήσιμη και πρακτική μετρική της απόδοσης ενός ταξινομητή. Ωστόσο, δεν αρκεί για μια ολοκληρωμένη μελέτη της απόδοσής του. Είναι τυπικό για όλα τα προβλήματα machine learning να χρησιμοποιούμε διαφορετικές μετρικές για να μελετήσουμε τις ιδιότητες των δεδομένων. \n","\n","Καταρχάς, ας ξαναφέρουμε το Iris dataset και τον kNN και ας κάνουμε προβλέψεις με τον default kNN (είναι ακριβώς ο κώδικας από το προηγούμενο notebook σε ένα cell)"]},{"cell_type":"code","metadata":{"id":"M7S5oMasoiux","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993287773,"user_tz":-120,"elapsed":12718,"user":{"displayName":"Savvas Sifnaios","photoUrl":"","userId":"09827535660052856195"}},"outputId":"1d146131-25e6-418b-e15d-80884430d0d9"},"source":["# Load Iris and organize our data\n","from sklearn.datasets import load_iris\n","from sklearn.metrics import confusion_matrix\n","data = load_iris()\n","label_names = data['target_names']\n","labels = data['target']\n","feature_names = data['feature_names']\n","features = data['data']\n","# Χρησιμοποιούμε τη γνωστή train_test_split για να διαχωρίσουμε σε train και test set\n","# το (int) όρισμα \"random_state\" είναι το seed της γεννήτριας τυχαίων αριθμών (αν του δώσουμε τιμή θα παράξει την ίδια σειρά τυχαίων αριθμών)\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.40, random_state=78)\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","for i in range(1,40):\n","  knn = KNeighborsClassifier(n_neighbors=i)\n","  knn.fit(X_train, y_train)\n","  pred = knn.predict(X_test)\n","  # Compute confusion matrix\n","  cnf_matrix = confusion_matrix(y_test, pred)\n","  # τυπώνουμε τα labels\n","  print(label_names, \"\\n\")\n","  # τυπώνουμε το confusion matrix\n","  print(cnf_matrix)  "],"execution_count":2,"outputs":[{"output_type":"stream","text":["['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 22  1]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  2 15]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  1 16]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  2 15]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 20  3]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 21  2]\n"," [ 0  0 17]]\n","['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 20  3]\n"," [ 0  0 17]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Swg5-nF2pbsx"},"source":["Η βάση για τις μετρικές απόδοσης των ταξινομητών είναι ο πίνακας σύγχυσης (confusion matrix). O πίνακας σύχγυσης $C$  είναι τέτοιος ώστε το $C_{i, j}$ είναι ίσο με τα δείγματα που ενώ ανήκουν στην κατηγορία $i$ ταξινομήθηκαν στην κατηγορία  $j$. Για το Iris, στο συγκεκριμένο train/test split, o πίνακας σύγχυσης είναι:"]},{"cell_type":"code","metadata":{"id":"mcMHwGmJN4pZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993363665,"user_tz":-120,"elapsed":775,"user":{"displayName":"Savvas Sifnaios","photoUrl":"","userId":"09827535660052856195"}},"outputId":"be5ae74b-e102-4d95-ccf2-92e48df0a40f"},"source":["from sklearn.metrics import confusion_matrix\n","# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y_test, pred)\n","# τυπώνουμε τα labels\n","print(label_names, \"\\n\")\n","# τυπώνουμε το confusion matrix\n","print(cnf_matrix)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['setosa' 'versicolor' 'virginica'] \n","\n","[[20  0  0]\n"," [ 0 20  3]\n"," [ 0  0 17]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UUP5FyOdN4pe"},"source":["που σημαίνει ότι 1 δείγμα που άνηκε κανονικά στο είδος versicolor ταξινομήθηκε λανθασμένα στο είδος virginica. Τα στοιχεία της διαγωνίου είναι αληθινά θετικά δείγματα (true positive) της κάθε κλάσης. Για κάθε κλάση $i$ τα στοιχεία της γραμμής $i$ εκτός της διαγωνίου είναι λάνθασμένα αρνητικά δείγματα (false negative) της κλάσης και τα στοιχεία της κολώνας $i$ εκτός της διαγωνίου είναι λανθασμένα θετικά δείγματα (false positive) της κλάσης. \n","\n","\n","<figure>\n","  <center>\n","  <img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png\" alt=\"Confusion Matrix\">\n","   <figcaption>Confusion matrix στο Iris - αλλος ταξινομητής (SVM)</figcaption>\n","  </center>\n","</figure>\n","\n","\n","Σε περίπτωση δυαδικού ταξινομητή $C_{0,0}$ είναι τα αληθινά αρνητικά δείγματα (true negative, η κλάση 0 θεωρείται η αρνητική), $C_{1,0}$ είναι τα λανθασμένα αρνητικά δείγματα, $C_{1,1}$ τα αληθινά θετικά δείγματα και $C_{0,1}$ τα λανθασμένα θετικά. Για παράδειγμα:"]},{"cell_type":"code","metadata":{"id":"knmN5cfFN4pf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993465722,"user_tz":-120,"elapsed":782,"user":{"displayName":"Savvas Sifnaios","photoUrl":"","userId":"09827535660052856195"}},"outputId":"7bbc3f71-ef71-437c-8193-5a5c657fefbf"},"source":["# παράδειγμα confusion matrix σε δυαδική ταξινόμηση\n","tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n","print(tn, fp, fn, tp)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["0 2 1 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L5YF7Z4BN4pi"},"source":["Συχνά στην δυαδική ταξινόμηση θεωρούμε θετική την πιο σπάνια κλάση ή το φαινόμενο προς εντοπισμό (πχ διαβητικός). \n","\n","![CMMulti2](https://drive.google.com/uc?id=143alsFB2Xbjovf2kCcErg2FKf6XFLyn-)\n","\n","![CMMulti21](https://drive.google.com/uc?id=1Oqen4t9o_IBGHXzWjN9s_RcS3MAfJZuP)\n","Ορίζουμε:\n","Ακρίβεια -Precision- ($P$) είναι ο λόγος των true positives ($T_p$) ως προς τον αριθμό των true positives συν τον αριθμό των false positives ($F_p$).\n","$$P = \\frac{T_p}{T_p+F_p}$$\n","Ανάκληση -Recall- ($R$) είναι ο λόγος των true positives ($T_p$) ως προς τον αριθμό των true positives συν τον αριθμό των false negatives ($F_n$).\n","$$R = \\frac{T_p}{T_p + F_n}$$\n","Συχνά χρησιμοποιούμε και το ($F_1$) score, το οποίο είναι ο αρμονικός μέσος της ακρίβειας και της ανάκλησης.\n","$$F1 = 2\\frac{P \\times R}{P+R}$$\n","Ιδανικά θέλουμε και υψηλή ακρίβεια και υψηλή ανάκληση, ωστόσο μεταξύ της ακρίβειας και της ανάκλησης υπάρχει γενικά trade-off. Στην οριακή περίπτωση του ταξινομητή που επιστρέφει σταθερά μόνο τη θετική κλάση για παράδειγμα, η ανάκληση θα είναι 1 αλλά η ακρίβεια θα έχει τη μικρότερη δυνατή τιμή της. Γενικά, κατεβάζοντας το κατώφλι της απόφασης του ταξινομητή, αυξάνουμε την ανάκληση και μειώνουμε την ακρίβεια και αντιστρόφως.\n","\n","Στην πράξη και ειδικά σε μη ισορροπημένα datasets χρησιμοποιούμε την ακρίβεια, ανάκληση και το F1 πιο συχνά από την πιστότητα. Επίσης, ανάλογα την εφαρμογή μπορεί να μας ενδιαφέρει περισσότερο ένα συγκεκριμένο metric, πχ η ανάκληση (πχ στη διάγνωση μιας ασθένειας) ή η ακρίβεια (πχ σε μια οικονομική απόφαση)."]},{"cell_type":"code","metadata":{"id":"hbaie_yIN4pk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993551195,"user_tz":-120,"elapsed":772,"user":{"displayName":"Savvas Sifnaios","photoUrl":"","userId":"09827535660052856195"}},"outputId":"cf3543f2-63fa-41f3-ee0c-3578bf210ea2"},"source":["\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","# εκτυπώνουμε 4 πίνακες, precision, recall, F1 και support. Support είναι ο συνολικός αριθμός προβλέψεων σε κάθε κλάση\n","# το πρώτο στοιχείο του κάθε πίνακα είναι η κλάση setosa, το δεύτερο η versicolor και το τρίτο η virginica\n","print(precision_recall_fscore_support(y_test, pred, average=None), \"\\n\")\n","\n","# εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας υπόψη συνολικά (αθροίζοντας εκτός κλάσεων) τα δείγματα (average = micro).\n","print(precision_recall_fscore_support(y_test, pred, average='micro'), \"\\n\")\n","\n","# εκτυπώνουμε το μέσο όρο των precision, recall και F1 θεωρώντας ότι οι κλάσεις έχουν το ίδιο βάρος (average = macro)\n","print(precision_recall_fscore_support(y_test, pred, average='macro'), \"\\n\")\n","\n","# εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας. Με average = weighted κάθε κλάση μετρά στο μέσο όρο ανάλογα με το support της.\n","print(precision_recall_fscore_support(y_test, pred, average='weighted'), \"\\n\")\n","\n","# η classification_report τυπώνει πιο ωραία οπτικά σε string τα αποτελέσματα\n","# πρώτα για κάθε κλάση και μετά με μέσους όρους\n","print(\"a\")\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, pred, target_names=label_names))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(array([1.  , 1.  , 0.85]), array([1.        , 0.86956522, 1.        ]), array([1.        , 0.93023256, 0.91891892]), array([20, 23, 17])) \n","\n","(0.95, 0.95, 0.9500000000000001, None) \n","\n","(0.9500000000000001, 0.9565217391304347, 0.9497171590194845, None) \n","\n","(0.9575, 0.95, 0.9502828409805153, None) \n","\n","a\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        20\n","  versicolor       1.00      0.87      0.93        23\n","   virginica       0.85      1.00      0.92        17\n","\n","    accuracy                           0.95        60\n","   macro avg       0.95      0.96      0.95        60\n","weighted avg       0.96      0.95      0.95        60\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3NgAbLr4ZhSB"},"source":["Documentation από το scikit σχετικά με την αξιολόγηση των μοντέλων:\n","\n","* [sklearn.metrics.precision_recall_fscore_support](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)\n","* [Model evaluation: quantifying the quality of predictions](http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification)\n","* [Multiclass and multilabel classification](http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification)\n","\n","Σημειώστε ότι όταν η classification report μέχρι το version 0.19 του scikit τυπώνει μόνο ένα μέσο όρο, τον weighted. (σχετική συζήτηση [εδώ](https://stackoverflow.com/questions/23914472/strange-f1-score-result-using-scikit-learn))."]},{"cell_type":"markdown","metadata":{"id":"yD1gabVouubh"},"source":["# Άσκηση: Σύγκριση του Gausian Naive Bayes και του kNN στo Pima Indians Diabetes dataset\n","![1889 Photograph shows half-length portrait of two Pima Indians, facing front, wearing bead necklaces.](https://i.pinimg.com/236x/60/05/76/600576905d4ad5bb1a9c3e3387b397ca--pima-indians-native-american-indians.jpg \"1889 Photograph shows half-length portrait of two Pima Indians, facing front, wearing bead necklaces.\")\n","\n","Διαβάστε το [\"pima-indians-diabetes.data.csv\"](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv) σε ένα numpy array data και ξεχωρίστε features και labels.\n","\n","Για 40% test set: \n","1. υπολογίστε την πρόβλεψη του Gaussian Naive Bayes με τη μέθοδο predict(). \n","2. πάρτε τις προβλέψεις ενός kNN με k=5\n","3. Για έναν ταξινομητή kNN, με 3-fold cross validation και με μετρική 'f1_weighted' υπολογίστε το βέλτιστο k στο train set (maximum k=50). \n","4. εκτυπώστε με την \"classification_report\" τα precision, recall, f1, support για τον NB, τον kNN με k=5 και με το k που έχει προκύψει από cross validation.\n","5. Κάντε 3 runs και αποθηκεύστε σε ένα κελί markdown το average F1 του non optimized και του optimized kNN. Πόσο % έχει βελτιβωθεί η επίδοσή του; \n","\n","hint: Για τη δημιουργία πινάκων σε markdown μπορείτε να χρησιμοποιείτε ένα [markdown table generator](https://www.tablesgenerator.com/markdown_tables)"]},{"cell_type":"code","metadata":{"id":"eXQ7a7Nt_5Zz","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"ok","timestamp":1605147330835,"user_tz":-120,"elapsed":862,"user":{"displayName":"Tasos Kopsidas","photoUrl":"","userId":"04506877865467160689"}},"outputId":"a3746bc9-974b-4de7-b2f7-5924a213dc13"},"source":["import pandas as pd\n","df = pd.read_csv(\"pima-indians-diabetes.data.csv\", header=None)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>10</td>\n","      <td>101</td>\n","      <td>76</td>\n","      <td>48</td>\n","      <td>180</td>\n","      <td>32.9</td>\n","      <td>0.171</td>\n","      <td>63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>2</td>\n","      <td>122</td>\n","      <td>70</td>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>36.8</td>\n","      <td>0.340</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>5</td>\n","      <td>121</td>\n","      <td>72</td>\n","      <td>23</td>\n","      <td>112</td>\n","      <td>26.2</td>\n","      <td>0.245</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>1</td>\n","      <td>126</td>\n","      <td>60</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.1</td>\n","      <td>0.349</td>\n","      <td>47</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>1</td>\n","      <td>93</td>\n","      <td>70</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>30.4</td>\n","      <td>0.315</td>\n","      <td>23</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 9 columns</p>\n","</div>"],"text/plain":["      0    1   2   3    4     5      6   7  8\n","0     6  148  72  35    0  33.6  0.627  50  1\n","1     1   85  66  29    0  26.6  0.351  31  0\n","2     8  183  64   0    0  23.3  0.672  32  1\n","3     1   89  66  23   94  28.1  0.167  21  0\n","4     0  137  40  35  168  43.1  2.288  33  1\n","..   ..  ...  ..  ..  ...   ...    ...  .. ..\n","763  10  101  76  48  180  32.9  0.171  63  0\n","764   2  122  70  27    0  36.8  0.340  27  0\n","765   5  121  72  23  112  26.2  0.245  30  0\n","766   1  126  60   0    0  30.1  0.349  47  1\n","767   1   93  70  31    0  30.4  0.315  23  0\n","\n","[768 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"OxH2PXS5lvf6"},"source":["labels_df = df.iloc[:, [8]] # τα labels είναι στη δεύτερη κολώνα\n","features_df = df.iloc[:, 0:8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cN41p8K_mS87","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605147335390,"user_tz":-120,"elapsed":690,"user":{"displayName":"Tasos Kopsidas","photoUrl":"","userId":"04506877865467160689"}},"outputId":"8ee64541-083d-4183-84df-52db3b7c221d"},"source":["import numpy as np\n","features = features_df.values\n","labels = labels_df.values.reshape(768,)\n","print(labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(768,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yj69ZPiJmUrM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605147337380,"user_tz":-120,"elapsed":821,"user":{"displayName":"Tasos Kopsidas","photoUrl":"","userId":"04506877865467160689"}},"outputId":"2bf6658d-d620-4c65-bfae-ede292e07cfc"},"source":["labels.astype(int)\n","print (\"frequencies:\", np.bincount(labels))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["frequencies: [500 268]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J1GGPEHBnYUE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605147348694,"user_tz":-120,"elapsed":590,"user":{"displayName":"Tasos Kopsidas","photoUrl":"","userId":"04506877865467160689"}},"outputId":"cbdfb53f-7785-40a9-eeef-ad134c4293b6"},"source":["print(\"f1 {}, f2 {}\".format(np.bincount(labels)[0]/labels.shape, \"bf\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["f1 [0.65104167], f2 bf\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7DcaAzFppBt"},"source":["from sklearn.model_selection import train_test_split\n","\n","# Split our data\n","train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"frZKbHIirmGp"},"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()\n","# κάνουμε εκπαίδευση (fit) δηλαδή ουσιαστικά υπολογίζουμε μέση τιμή και διακύμανση για όλα τα χαρακτηριστικά και κλάσεις στο training set\n","model = gnb.fit(train, train_labels)\n","# η GaussianNB έχει builtin μέθοδο υπολογισμό accuracy. Αποθηκεύουμε την τιμή της στον πίνακά μας με τα αποτελέσματα από τα άλλα classifiers\n","pred_gnb = model.predict(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"21UgcuBH6kI4"},"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier(n_neighbors=5)\n","model = knn.fit(train,train_labels)\n","pred_knn5 = model.predict(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCi7CRxTSPKJ"},"source":["# φτιάχνουμε μια λίστα από το 1 έως το 50\n","myList = list(range(1,50))\n","# Κρατάμε μόνο τα περιττά k\n","neighbors = list(filter(lambda x: x % 2 != 0, myList))\n","\n","# perform 3-fold cross validation\n","max = -1\n","max_k = -1\n","for k in neighbors:\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    scores = cross_val_score(knn, train, train_labels, cv=3, scoring='f1_weighted')\n","    max, max_k = (scores.mean(), k) if scores.mean() > max  else (max, max_k)\n","knn_opt = KNeighborsClassifier(n_neighbors=max_k)\n","model = knn_opt.fit(train,train_labels)\n","pred_knn_opt = model.predict(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BdGacr1u9yeh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605147379568,"user_tz":-120,"elapsed":900,"user":{"displayName":"Tasos Kopsidas","photoUrl":"","userId":"04506877865467160689"}},"outputId":"647ec63f-6ee2-4326-d8a9-17f524010d48"},"source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(test_labels, pred_gnb))\n","print(classification_report(test_labels, pred_knn5))\n","print(classification_report(test_labels, pred_knn_opt))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.80      0.82       209\n","           1       0.61      0.65      0.63        99\n","\n","    accuracy                           0.75       308\n","   macro avg       0.72      0.73      0.72       308\n","weighted avg       0.76      0.75      0.76       308\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.80      0.80       209\n","           1       0.58      0.58      0.58        99\n","\n","    accuracy                           0.73       308\n","   macro avg       0.69      0.69      0.69       308\n","weighted avg       0.73      0.73      0.73       308\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.81      0.81       209\n","           1       0.60      0.59      0.59        99\n","\n","    accuracy                           0.74       308\n","   macro avg       0.70      0.70      0.70       308\n","weighted avg       0.74      0.74      0.74       308\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hWEO4qry-jJr"},"source":[""],"execution_count":null,"outputs":[]}]}