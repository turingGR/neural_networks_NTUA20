{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###1. Load data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import csv\n",
    "datafile=\"ionosphere.data.csv\"\n",
    "X=np.zeros((351,34),dtype='float')\n",
    "Y=np.zeros((351,),dtype='bool')\n",
    " \n",
    "with open(datafile,'r') as input_file:\n",
    "    reader=csv.reader(input_file)\n",
    "    for i, row in enumerate(reader):\n",
    "        data=[float(datum) for datum in row[:-1]]\n",
    "        X[i]=data\n",
    "        # 1 if the class is 'g', 0 otherwise\n",
    "        Y[i]=row[-1]=='g'\n",
    "print(X.shape)\n",
    " \n",
    "###2. Observe data\n",
    "import pandas as pd \n",
    "def rstr(df):\n",
    "    return df.shape, df.apply(lambda x:[x.unique()])\n",
    "print('\\n''structure of data:''\\n',rstr(pd.DataFrame(X)))\n",
    "#structure of data:\n",
    "# ((351, 34), 0                                          [[1.0, 0.0]]\n",
    "#1                                               [[0.0]]\n",
    "#2     [[0.99539, 1.0, 0.02337, 0.97588, 0.0, 0.96355...\n",
    "#3     [[-0.05889, -0.18829, -0.03365, -0.45161, -0.0...\n",
    "#4     [[0.85243, 0.93035, 1.0, 0.9414, -0.09924, 0.9...\n",
    "#5     [[0.02306, -0.36156, 0.00485, 1.0, 0.06531, -0...\n",
    "#6     [[0.83398, -0.10868, 1.0, 0.71216, 0.92106, -0...\n",
    "#7     [[-0.37708, -0.93597, -0.12062, -1.0, -0.23255...\n",
    "#8     [[1.0, 0.88965, 0.0, 0.77152, 0.14706, 0.85996...\n",
    "#9     [[0.0376, -0.04549, 0.01198, 0.0, -0.16399, 0....\n",
    "#10    [[0.85243, 0.50874, 0.73082, 0.0, 0.52798, 0.0...\n",
    "#11    [[-0.17755, -0.67743, 0.05346, 0.0, -0.20275, ...\n",
    "#12    [[0.59755, 0.34432, 0.85443, 0.0, 0.56409, 0.7...\n",
    "#13    [[-0.44945, -0.69707, 0.00827, 0.0, -0.00712, ...\n",
    "#14    [[0.60536, -0.51685, 0.54591, -1.0, 0.34395, -...\n",
    "#15    [[-0.38223, -0.97515, 0.00299, 0.14516, -0.274...\n",
    "#16    [[0.84356, 0.05499, 0.83775, 0.54094, 0.5294, ...\n",
    "#17    [[-0.38542, -0.62237, -0.13644, -0.3933, -0.21...\n",
    "#18    [[0.58212, 0.33109, 0.75535, -1.0, 0.45107, -0...\n",
    "#19    [[-0.32192, -1.0, -0.0854, -0.54467, -0.17813,...\n",
    "#20    [[0.56971, -0.13151, 0.70887, -0.69975, 0.0598...\n",
    "#21    [[-0.29674, -0.453, -0.27502, 1.0, -0.35575, 0...\n",
    "#22    [[0.36946, -0.18056, 0.43385, 0.0, 0.02309, 0....\n",
    "#23    [[-0.47357, -0.35734, -0.12062, 0.0, -0.52879,...\n",
    "#24    [[0.56811, -0.20332, 0.57528, 1.0, 0.03286, 0....\n",
    "#25    [[-0.51171, -0.26569, -0.4022, 0.90695, -0.651...\n",
    "#26    [[0.41078, -0.20468, 0.58984, 0.51613, 0.1329,...\n",
    "#27    [[-0.46168, -0.18401, -0.22145, 1.0, -0.53206,...\n",
    "#28    [[0.21266, -0.1904, 0.431, 1.0, 0.02431, -0.07...\n",
    "#29    [[-0.3409, -0.11593, -0.17365, -0.20099, -0.62...\n",
    "#30    [[0.42267, -0.16626, 0.60436, 0.25682, -0.0570...\n",
    "#31    [[-0.54487, -0.06288, -0.2418, 1.0, -0.59573, ...\n",
    "#32    [[0.18641, -0.13738, 0.56045, -0.32382, -0.046...\n",
    "#33    [[-0.453, -0.02447, -0.38238, 1.0, -0.65697, 0...\n",
    " \n",
    "###3. Preprocess data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_transformed = MinMaxScaler().fit_transform(X)\n",
    " \n",
    "###4. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, Y, random_state=14)\n",
    "print(\"There are %s samples in the training dataset\"%format(X_train.shape[0]))\n",
    "print(\"There are {} samples in the testing dataset\".format(X_test.shape[0]))\n",
    "print(\"Each sample has %i features\" %X_train.shape[1])\n",
    "#There are 263 samples in the training dataset\n",
    "#There are 88 samples in the testing dataset\n",
    "#Each sample has 34 features\n",
    " \n",
    "###5. Simply Fit the model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform')\n",
    "KNN_io=KNeighborsClassifier()\n",
    "KNN_io.fit(X_train,y_train)\n",
    " \n",
    "###6. Validate if you want to\n",
    "from sklearn.model_selection import cross_val_score\n",
    "trans_scores = cross_val_score(KNN_io, X_transformed, Y, scoring='accuracy')\n",
    "average_accuracy = np.mean(trans_scores) * 100\n",
    "print(\"The average accuracy is {0:.1f}%\".format(average_accuracy))\n",
    "#The average accuracy is 82.3%\n",
    " \n",
    "###7. Test the model\n",
    "y_predicted = KNN_io.predict(X_test)\n",
    "accuracy = np.mean(y_test == y_predicted) * 100\n",
    "print(\"The accuracy is {0:.1f}%\".format(accuracy))\n",
    "#The accuracy is 86.4%\n",
    " \n",
    "###8. Do it in pipeline if you want to\n",
    "from sklearn.pipeline import Pipeline\n",
    "scaling_pipeline = Pipeline([('scale', MinMaxScaler()),\n",
    "    ('predict', KNeighborsClassifier())])\n",
    "pipe_scores = cross_val_score(scaling_pipeline, X, Y, scoring='accuracy')\n",
    "print(\"The average accuracy for pipeline is {0:.1f}%\"\n",
    "    .format(np.mean(pipe_scores) * 100))\n",
    "#The average accuracy for pipeline is 82.3%\n",
    " \n",
    "###9. Gridsearch to tune parameters \n",
    "avg_scores = []\n",
    "all_scores = []\n",
    "parameter_values = list(range(1, 21))  # Including 20\n",
    "for n_neighbors in parameter_values:\n",
    "    KNN_grid = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=n_neighbors, p=2,\n",
    "           weights='uniform')\n",
    "    grid_scores = cross_val_score(KNN_grid, X_transformed, Y, scoring='accuracy')\n",
    "    avg_scores.append(np.mean(grid_scores))\n",
    "    all_scores.append(grid_scores)\n",
    "print(\"The gridsearch-based average accuracy is: \",avg_scores)\n",
    "#The gridsearch-based average accuracy is:  [0.83475783475783472, 0.85754985754985746, \n",
    "#0.83760683760683763, 0.84330484330484323, 0.8233618233618234, 0.84045584045584043, \n",
    "#0.80911680911680917, 0.84045584045584043, 0.81766381766381768, 0.83190883190883191, \n",
    "#0.79487179487179482, 0.81196581196581208, 0.79487179487179482, 0.80626780626780625, \n",
    "#0.78917378917378922, 0.79202279202279202, 0.7834757834757835, 0.78917378917378922, \n",
    "#0.77777777777777779, 0.79487179487179482]\n",
    " \n",
    "###10. Visualize\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(32,20))\n",
    "plt.plot(parameter_values, avg_scores, '-o', linewidth=5, markersize=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
